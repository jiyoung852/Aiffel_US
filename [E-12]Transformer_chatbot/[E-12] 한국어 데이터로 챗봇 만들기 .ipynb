{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd57a06",
   "metadata": {},
   "source": [
    "# 트랜스포머로 만드는 대화형 챗봇\n",
    "- 영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜봅시다.\n",
    "\n",
    "\n",
    "### **루브릭 평가 기준**\n",
    "\n",
    "|<center>평가문항</center>|<center>상세기준</center>|\n",
    "|:------|:------|\n",
    "|1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.|공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.|\n",
    "|2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.|구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.|\n",
    "|3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.|한국어 입력문장에 그럴듯한 한국어로 답변을 리턴하였다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d58a43",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기\n",
    "- 송영숙님이 공개한 챗봇 데이터를 사용\n",
    "[songys/Chatbot_data](https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8526e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11e41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5a002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6b84c",
   "metadata": {},
   "source": [
    "- 멀티 헤드 어텐션을 구현\n",
    "- 내부적으로는 스케일드 닷 프로덕트 어텐션 함수를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a017139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637146fe",
   "metadata": {},
   "source": [
    "### 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5bf073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d17816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f91bf2",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "538df014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4a0f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233fbe8",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b90ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e94cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a24bc80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/transformer_chatbot/data/ChatbotData .csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_dataset = os.getenv(\"HOME\")+\"/aiffel/transformer_chatbot/data/ChatbotData .csv\"\n",
    "path_to_conversations = path_to_dataset\n",
    "path_to_conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4daee112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 30000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8531d2b",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기\n",
    "- 한글이므로 전처리 과정에 한글도 포함 \n",
    "- 숫자도 포함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0ff7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  # sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  # 한글, 알파벳, 숫자, \n",
    "  sentence = re.sub(r\"[^가-힣a-zA-Z0-9?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aae817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_conversations, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "    conversation = []\n",
    "    for line in lines[1:]:\n",
    "        parts = line.split(',')\n",
    "        conversation.append([line for line in parts[0:2]])\n",
    "\n",
    "        \n",
    "    for i in range(len(conversation) - 1):\n",
    "        # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "        inputs.append(preprocess_sentence(conversation[i][0]))\n",
    "        outputs.append(preprocess_sentence(conversation[i][1]))\n",
    "\n",
    "    if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "\n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b43c1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11822\n",
      "전체 샘플 수 : 11822\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8351271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: 가스비 장난 아님\n",
      "전처리 후의 22번째 답변 샘플: 다음 달에는 더 절약해봐요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8776f5a",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c82ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e8ed1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8138]\n",
      "END_TOKEN의 번호 : [8139]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c8cdaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8140\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "550f7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5736, 607, 2478, 4139]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2347, 7482, 7, 6245, 96, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29c226",
   "metadata": {},
   "source": [
    "### 익스 8번 뉴스 요약 코드 참고\n",
    "- 거의 포함 될 수 있는 길이 11로 세팅 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e47a8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions 최대 길이 : 16\n",
      "questions 평균 길이 : 3.9260700389105057\n",
      "answers 최대 길이 : 24\n",
      "answers 평균 길이 : 4.685078666892235\n"
     ]
    }
   ],
   "source": [
    "questions_len = [len(s.split()) for s in questions]\n",
    "answers_len = [len(s.split()) for s in answers]\n",
    "print(f'questions 최대 길이 : {np.max(questions_len)}')\n",
    "print(f'questions 평균 길이 : {np.mean(questions_len)}')\n",
    "print(f'answers 최대 길이 : {np.max(answers_len)}')\n",
    "print(f'answers 평균 길이 : {np.mean(answers_len)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "babfd615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea368860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 허용 길이 지정\n",
    "MAX_LENGTH = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3be5ce1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e52fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8140\n",
      "필터링 후의 질문 샘플 개수: 10166\n",
      "필터링 후의 답변 샘플 개수: 10166\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3080bf",
   "metadata": {},
   "source": [
    "교사 강요(Teacher Forcing) 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "008501ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978fe96",
   "metadata": {},
   "source": [
    "# Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec66f805",
   "metadata": {},
   "source": [
    "트랜스포머 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60af59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94396d73",
   "metadata": {},
   "source": [
    "모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d49e592f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3138048     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3665408     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   2091980     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,895,436\n",
      "Trainable params: 8,895,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503735e",
   "metadata": {},
   "source": [
    "손실 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4160b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a11aa",
   "metadata": {},
   "source": [
    "커스텀 된 학습률(Learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "579789a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "217b1d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def416d",
   "metadata": {},
   "source": [
    "모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40bf17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38a3dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159/159 [==============================] - 11s 29ms/step - loss: 5.2117 - accuracy: 0.0900\n",
      "Epoch 2/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 4.2906 - accuracy: 0.1890\n",
      "Epoch 3/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.5747 - accuracy: 0.1936\n",
      "Epoch 4/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.2560 - accuracy: 0.2016\n",
      "Epoch 5/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.0603 - accuracy: 0.2131\n",
      "Epoch 6/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.8720 - accuracy: 0.2241\n",
      "Epoch 7/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.6703 - accuracy: 0.2421\n",
      "Epoch 8/20\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 2.4419 - accuracy: 0.2670\n",
      "Epoch 9/20\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 2.1896 - accuracy: 0.2976\n",
      "Epoch 10/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.9258 - accuracy: 0.3278\n",
      "Epoch 11/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.6472 - accuracy: 0.3623\n",
      "Epoch 12/20\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 1.3711 - accuracy: 0.3974\n",
      "Epoch 13/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.1055 - accuracy: 0.4343\n",
      "Epoch 14/20\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 0.8634 - accuracy: 0.4707\n",
      "Epoch 15/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.6502 - accuracy: 0.5043\n",
      "Epoch 16/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.4767 - accuracy: 0.5333\n",
      "Epoch 17/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.3375 - accuracy: 0.5592\n",
      "Epoch 18/20\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 0.2408 - accuracy: 0.5766\n",
      "Epoch 19/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1779 - accuracy: 0.5868\n",
      "Epoch 20/20\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1384 - accuracy: 0.5932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf83ace250>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da7343",
   "metadata": {},
   "source": [
    "# Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dae7e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331  86  30  5  1059  7  8332]]\n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "        # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "982df49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 함수\n",
    "def sentence_generation(sentence):\n",
    "    # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a932d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 사랑이 깊이 생각하지 말아요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 영화는 데이트의 기본이죠 .\n",
      "입력 : 오늘 뭐먹지?\n",
      "출력 : 정확하게 말씀해 주세요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 사람은 외로운 동물이죠 .\n",
      "입력 : 사랑해\n",
      "출력 : 상대방에게 전해보세요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'상대방에게 전해보세요 .'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df2abf",
   "metadata": {},
   "source": [
    "# 두번째 시도 \n",
    "- D_MODEL = 512\n",
    "- DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87346f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    7323648     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    9426944     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   4175820     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,926,412\n",
      "Trainable params: 20,926,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.5 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c5c01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "913a4530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "159/159 [==============================] - 12s 40ms/step - loss: 5.0963 - accuracy: 0.0753\n",
      "Epoch 2/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 4.0158 - accuracy: 0.1588\n",
      "Epoch 3/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 3.5338 - accuracy: 0.1927\n",
      "Epoch 4/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 3.3979 - accuracy: 0.1945\n",
      "Epoch 5/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 3.2878 - accuracy: 0.1968\n",
      "Epoch 6/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 3.1926 - accuracy: 0.2024\n",
      "Epoch 7/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 3.0988 - accuracy: 0.2088\n",
      "Epoch 8/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 3.0023 - accuracy: 0.2142\n",
      "Epoch 9/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 2.8864 - accuracy: 0.2214\n",
      "Epoch 10/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 2.7514 - accuracy: 0.2301\n",
      "Epoch 11/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 2.5936 - accuracy: 0.2422\n",
      "Epoch 12/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 2.4188 - accuracy: 0.2578\n",
      "Epoch 13/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 2.2351 - accuracy: 0.2760\n",
      "Epoch 14/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 2.0477 - accuracy: 0.2951\n",
      "Epoch 15/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 1.8751 - accuracy: 0.3135\n",
      "Epoch 16/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 1.7098 - accuracy: 0.3327\n",
      "Epoch 17/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 1.5635 - accuracy: 0.3487\n",
      "Epoch 18/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 1.4403 - accuracy: 0.3645\n",
      "Epoch 19/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 1.3337 - accuracy: 0.3784\n",
      "Epoch 20/20\n",
      "159/159 [==============================] - 6s 40ms/step - loss: 1.2428 - accuracy: 0.3920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdef4689d60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9274f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 혼자 풀릴 때까지 놔둬야하는데 기다리는게 힘들 거예요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 아무래도 그렇죠 .\n",
      "입력 : 오늘 뭐먹지?\n",
      "출력 : 혼자 힘들어하지 마세요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 저도 듣고 싶어요 .\n",
      "입력 : 사랑해\n",
      "출력 : 좋은 소식이네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 소식이네요 .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a445c8",
   "metadata": {},
   "source": [
    "# 세번째 시도 \n",
    "- DROPOUT = 0.5\n",
    "- EPOCHS =50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47d11129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3138048     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3665408     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   2091980     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,895,436\n",
      "Trainable params: 8,895,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.5 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "926aefe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "159/159 [==============================] - 10s 29ms/step - loss: 5.1866 - accuracy: 0.0959\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 4.2965 - accuracy: 0.1877\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.5956 - accuracy: 0.1935\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.2685 - accuracy: 0.2011\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.0661 - accuracy: 0.2124\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.8762 - accuracy: 0.2243\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.6690 - accuracy: 0.2424\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.4464 - accuracy: 0.2664\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.1964 - accuracy: 0.2959\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.9289 - accuracy: 0.3271\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.6525 - accuracy: 0.3606\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.3771 - accuracy: 0.3964\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.1130 - accuracy: 0.4321\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.8680 - accuracy: 0.4691\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.6583 - accuracy: 0.5019\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.4784 - accuracy: 0.5332\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.3411 - accuracy: 0.5584\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.2477 - accuracy: 0.5748\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1809 - accuracy: 0.5868\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1465 - accuracy: 0.5917\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1262 - accuracy: 0.5940\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1149 - accuracy: 0.5958\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1092 - accuracy: 0.5962\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1081 - accuracy: 0.5960\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.1011 - accuracy: 0.5981\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0977 - accuracy: 0.5978\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0874 - accuracy: 0.6002\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0779 - accuracy: 0.6025\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0724 - accuracy: 0.6040\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0644 - accuracy: 0.6059\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0560 - accuracy: 0.6074\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0532 - accuracy: 0.6088\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0477 - accuracy: 0.6101\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0458 - accuracy: 0.6104\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0415 - accuracy: 0.6117\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0389 - accuracy: 0.6122\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0368 - accuracy: 0.6127\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0336 - accuracy: 0.6135\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0348 - accuracy: 0.6131\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0307 - accuracy: 0.6143\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0294 - accuracy: 0.6148\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0283 - accuracy: 0.6149\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0262 - accuracy: 0.6154\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0261 - accuracy: 0.6153\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0233 - accuracy: 0.6159\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0220 - accuracy: 0.6164\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0226 - accuracy: 0.6163\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0218 - accuracy: 0.6164\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0207 - accuracy: 0.6165\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 0.0196 - accuracy: 0.6169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf040d0220>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "218b5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 정말 후회할 습관이에요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 성적자기결정권이있죠 .\n",
      "입력 : 오늘 뭐먹지?\n",
      "출력 : 색다른걸 드셔보세요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 믿기지 않겠어요 .\n",
      "입력 : 사랑해\n",
      "출력 : 하늘 만큼 땅 만큼 사랑해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'하늘 만큼 땅 만큼 사랑해요 .'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dac62a",
   "metadata": {},
   "source": [
    "# 네번째 시도\n",
    "- NUM_LAYERS = 4\n",
    "- DROPOUT = 0.3\n",
    "- EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2734ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    4192256     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    5246976     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   2091980     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,531,212\n",
      "Trainable params: 11,531,212\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.3 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69156c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "159/159 [==============================] - 18s 48ms/step - loss: 5.1957 - accuracy: 0.0775\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 4.3864 - accuracy: 0.1228\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 3.6739 - accuracy: 0.1923\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 3.4135 - accuracy: 0.1939\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 3.2504 - accuracy: 0.1996\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 3.1470 - accuracy: 0.2052\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 3.0587 - accuracy: 0.2087\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 2.9730 - accuracy: 0.2126\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 2.8870 - accuracy: 0.2167\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 2.7954 - accuracy: 0.2219\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 2.6966 - accuracy: 0.2288\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 2.5901 - accuracy: 0.2352\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 2.4700 - accuracy: 0.2447\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 2.3379 - accuracy: 0.2568\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 8s 47ms/step - loss: 2.1971 - accuracy: 0.2713\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 2.0550 - accuracy: 0.2872\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 7s 46ms/step - loss: 1.9102 - accuracy: 0.3038\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 8s 47ms/step - loss: 1.7643 - accuracy: 0.3229\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.6345 - accuracy: 0.3405\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.5151 - accuracy: 0.3578\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.4173 - accuracy: 0.3702\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.3301 - accuracy: 0.3834\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.2608 - accuracy: 0.3946\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.2177 - accuracy: 0.4013\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.1742 - accuracy: 0.4097\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.1479 - accuracy: 0.4141\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.1057 - accuracy: 0.4222\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 1.0756 - accuracy: 0.4290\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.0497 - accuracy: 0.4329\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.0275 - accuracy: 0.4370\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 1.0085 - accuracy: 0.4407\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.9939 - accuracy: 0.4433\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.9753 - accuracy: 0.4472\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.9639 - accuracy: 0.4484\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 0.9469 - accuracy: 0.4513\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 0.9357 - accuracy: 0.4529\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 8s 47ms/step - loss: 0.9261 - accuracy: 0.4532\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.9147 - accuracy: 0.4560\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.9022 - accuracy: 0.4576\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 0.8894 - accuracy: 0.4596\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 0.8835 - accuracy: 0.4608\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 8s 47ms/step - loss: 0.8726 - accuracy: 0.4621\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8599 - accuracy: 0.4629\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8542 - accuracy: 0.4642\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8435 - accuracy: 0.4658\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8360 - accuracy: 0.4667\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8251 - accuracy: 0.4685\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8209 - accuracy: 0.4686\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 8s 49ms/step - loss: 0.8158 - accuracy: 0.4698\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 8s 48ms/step - loss: 0.8061 - accuracy: 0.4706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdee14fca60>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f1c03a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 다른 사람이 답답할 거예요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 사람마다 다르겠지만 사귀고 난 후가 좋겠어요 .\n",
      "입력 : 오늘 뭐먹지?\n",
      "출력 : 하다보면 늘어요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 같이 고르는 것도 좋을 거 같아요 .\n",
      "입력 : 사랑해\n",
      "출력 : 저도 보고 싶어요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 보고 싶어요 .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207dad16",
   "metadata": {},
   "source": [
    "# 다섯번째 시도\n",
    "- UNITS = 1024\n",
    "- DROPOUT = 0.5\n",
    "- EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c29a000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3663360     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    4190720     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   2091980     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,946,060\n",
      "Trainable params: 9,946,060\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 1024 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.5 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "facca8f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "159/159 [==============================] - 10s 30ms/step - loss: 5.2599 - accuracy: 0.0687\n",
      "Epoch 2/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 4.4050 - accuracy: 0.1321\n",
      "Epoch 3/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.7021 - accuracy: 0.1914\n",
      "Epoch 4/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.4663 - accuracy: 0.1937\n",
      "Epoch 5/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.3289 - accuracy: 0.1958\n",
      "Epoch 6/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.2170 - accuracy: 0.1989\n",
      "Epoch 7/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.1302 - accuracy: 0.2048\n",
      "Epoch 8/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 3.0456 - accuracy: 0.2105\n",
      "Epoch 9/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.9556 - accuracy: 0.2152\n",
      "Epoch 10/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.8565 - accuracy: 0.2212\n",
      "Epoch 11/30\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 2.7414 - accuracy: 0.2286\n",
      "Epoch 12/30\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 2.6125 - accuracy: 0.2384\n",
      "Epoch 13/30\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 2.4673 - accuracy: 0.2500\n",
      "Epoch 14/30\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 2.3203 - accuracy: 0.2649\n",
      "Epoch 15/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.1690 - accuracy: 0.2792\n",
      "Epoch 16/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 2.0192 - accuracy: 0.2943\n",
      "Epoch 17/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.8754 - accuracy: 0.3106\n",
      "Epoch 18/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.7476 - accuracy: 0.3255\n",
      "Epoch 19/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.6308 - accuracy: 0.3374\n",
      "Epoch 20/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.5277 - accuracy: 0.3501\n",
      "Epoch 21/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.4393 - accuracy: 0.3620\n",
      "Epoch 22/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.3641 - accuracy: 0.3721\n",
      "Epoch 23/30\n",
      "159/159 [==============================] - 5s 30ms/step - loss: 1.3013 - accuracy: 0.3818\n",
      "Epoch 24/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.2456 - accuracy: 0.3917\n",
      "Epoch 25/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.2011 - accuracy: 0.3994\n",
      "Epoch 26/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.1627 - accuracy: 0.4070\n",
      "Epoch 27/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.1283 - accuracy: 0.4135\n",
      "Epoch 28/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.0892 - accuracy: 0.4199\n",
      "Epoch 29/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.0623 - accuracy: 0.4252\n",
      "Epoch 30/30\n",
      "159/159 [==============================] - 5s 29ms/step - loss: 1.0417 - accuracy: 0.4291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdee1382b20>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS = 30\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9793e4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 저도 반가워요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 직접 물어보는 게 좋을 것 같아요 .\n",
      "입력 : 오늘 뭐 먹지?\n",
      "출력 : 감기 조심하세요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 직장 스트레스가 심한가봐요 .\n",
      "입력 : 사랑해\n",
      "출력 : 저도 커피 좋아해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 커피 좋아해요 .'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐 먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a09aa00",
   "metadata": {},
   "source": [
    "# 여섯번째 시도 \n",
    "- NUM_LAYERS = 4\n",
    "- D_MODEL = 512\n",
    "- DROPOUT = 0.5\n",
    "- EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dae8dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    10479616    inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    14686208    dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   4175820     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,341,644\n",
      "Trainable params: 29,341,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.5 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "45f3b6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "159/159 [==============================] - 21s 65ms/step - loss: 5.0382 - accuracy: 0.0732\n",
      "Epoch 2/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 4.0648 - accuracy: 0.1032\n",
      "Epoch 3/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.5925 - accuracy: 0.1889\n",
      "Epoch 4/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.4297 - accuracy: 0.1937\n",
      "Epoch 5/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.3137 - accuracy: 0.1951\n",
      "Epoch 6/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.2328 - accuracy: 0.1972\n",
      "Epoch 7/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.1797 - accuracy: 0.1989\n",
      "Epoch 8/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.1349 - accuracy: 0.2024\n",
      "Epoch 9/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.0874 - accuracy: 0.2041\n",
      "Epoch 10/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 3.0346 - accuracy: 0.2065\n",
      "Epoch 11/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.9746 - accuracy: 0.2091\n",
      "Epoch 12/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.9203 - accuracy: 0.2124\n",
      "Epoch 13/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.8649 - accuracy: 0.2148\n",
      "Epoch 14/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.8127 - accuracy: 0.2178\n",
      "Epoch 15/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.7673 - accuracy: 0.2194\n",
      "Epoch 16/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.7192 - accuracy: 0.2212\n",
      "Epoch 17/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.6692 - accuracy: 0.2242\n",
      "Epoch 18/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.6207 - accuracy: 0.2259\n",
      "Epoch 19/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.5681 - accuracy: 0.2285\n",
      "Epoch 20/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.5132 - accuracy: 0.2312\n",
      "Epoch 21/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.4572 - accuracy: 0.2348\n",
      "Epoch 22/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.4029 - accuracy: 0.2377\n",
      "Epoch 23/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.3460 - accuracy: 0.2419\n",
      "Epoch 24/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.2888 - accuracy: 0.2446\n",
      "Epoch 25/30\n",
      "159/159 [==============================] - 10s 63ms/step - loss: 2.2292 - accuracy: 0.2498\n",
      "Epoch 26/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.1694 - accuracy: 0.2545\n",
      "Epoch 27/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.1032 - accuracy: 0.2615\n",
      "Epoch 28/30\n",
      "159/159 [==============================] - 10s 64ms/step - loss: 2.0362 - accuracy: 0.2668\n",
      "Epoch 29/30\n",
      "159/159 [==============================] - 10s 63ms/step - loss: 1.9800 - accuracy: 0.2732\n",
      "Epoch 30/30\n",
      "159/159 [==============================] - 10s 63ms/step - loss: 1.9176 - accuracy: 0.2805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdee13826d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS = 30\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3552293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 너무 충분히 많이 바쁜가봐요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 썸 나이는 중요하지 않아요 .\n",
      "입력 : 오늘 뭐 먹지?\n",
      "출력 : 제가 있잖아요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 잘 다녀 오세요 .\n",
      "입력 : 사랑해\n",
      "출력 : 너무 충분히 많이 바쁜가봐요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'너무 충분히 많이 바쁜가봐요 .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐 먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533c554",
   "metadata": {},
   "source": [
    "# 일곱번째 시도\n",
    "1번과 동일하고 \n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd328e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3138048     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3665408     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8140)   2091980     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,895,436\n",
      "Trainable params: 8,895,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11e11504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "159/159 [==============================] - 10s 29ms/step - loss: 5.2426 - accuracy: 0.1041\n",
      "Epoch 2/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 4.3201 - accuracy: 0.1912\n",
      "Epoch 3/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 3.5931 - accuracy: 0.1935\n",
      "Epoch 4/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 3.2648 - accuracy: 0.2012\n",
      "Epoch 5/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 3.0653 - accuracy: 0.2125\n",
      "Epoch 6/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 2.8751 - accuracy: 0.2255\n",
      "Epoch 7/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 2.6771 - accuracy: 0.2423\n",
      "Epoch 8/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 2.4551 - accuracy: 0.2659\n",
      "Epoch 9/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 2.2079 - accuracy: 0.2936\n",
      "Epoch 10/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 1.9379 - accuracy: 0.3260\n",
      "Epoch 11/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 1.6585 - accuracy: 0.3608\n",
      "Epoch 12/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 1.3814 - accuracy: 0.3949\n",
      "Epoch 13/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 1.1126 - accuracy: 0.4331\n",
      "Epoch 14/50\n",
      "159/159 [==============================] - 5s 28ms/step - loss: 0.8684 - accuracy: 0.4701\n",
      "Epoch 15/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.6522 - accuracy: 0.5034\n",
      "Epoch 16/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.4735 - accuracy: 0.5348\n",
      "Epoch 17/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.3361 - accuracy: 0.5597\n",
      "Epoch 18/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.2358 - accuracy: 0.5777\n",
      "Epoch 19/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.1739 - accuracy: 0.5881\n",
      "Epoch 20/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.1415 - accuracy: 0.5922\n",
      "Epoch 21/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.1216 - accuracy: 0.5956\n",
      "Epoch 22/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.1104 - accuracy: 0.5974\n",
      "Epoch 23/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.1050 - accuracy: 0.5975\n",
      "Epoch 24/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0998 - accuracy: 0.5988\n",
      "Epoch 25/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.1004 - accuracy: 0.5976\n",
      "Epoch 26/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0950 - accuracy: 0.5984\n",
      "Epoch 27/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0838 - accuracy: 0.6011\n",
      "Epoch 28/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0748 - accuracy: 0.6035\n",
      "Epoch 29/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0676 - accuracy: 0.6052\n",
      "Epoch 30/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0605 - accuracy: 0.6070\n",
      "Epoch 31/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0574 - accuracy: 0.6077\n",
      "Epoch 32/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0511 - accuracy: 0.6095\n",
      "Epoch 33/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0481 - accuracy: 0.6101\n",
      "Epoch 34/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0435 - accuracy: 0.6113\n",
      "Epoch 35/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0414 - accuracy: 0.6114\n",
      "Epoch 36/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0395 - accuracy: 0.6120\n",
      "Epoch 37/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0346 - accuracy: 0.6136\n",
      "Epoch 38/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0342 - accuracy: 0.6136\n",
      "Epoch 39/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0326 - accuracy: 0.6139\n",
      "Epoch 40/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0295 - accuracy: 0.6146\n",
      "Epoch 41/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0306 - accuracy: 0.6144\n",
      "Epoch 42/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0271 - accuracy: 0.6149\n",
      "Epoch 43/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0262 - accuracy: 0.6154\n",
      "Epoch 44/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0245 - accuracy: 0.6160\n",
      "Epoch 45/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0241 - accuracy: 0.6158\n",
      "Epoch 46/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0237 - accuracy: 0.6161\n",
      "Epoch 47/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0216 - accuracy: 0.6164\n",
      "Epoch 48/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0218 - accuracy: 0.6165\n",
      "Epoch 49/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0219 - accuracy: 0.6166\n",
      "Epoch 50/50\n",
      "159/159 [==============================] - 4s 28ms/step - loss: 0.0211 - accuracy: 0.6165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdee0b45940>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e0fda440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 내일 날씨는 어때?\n",
      "출력 : 조금씩 조금씩 해보세요 .\n",
      "입력 : 어떤 영화 좋아해?\n",
      "출력 : 최신 영화가 좋을 것 같아요 .\n",
      "입력 : 오늘 뭐 먹지?\n",
      "출력 : 색다른걸 드셔보세요 .\n",
      "입력 : 피곤하고 잠와\n",
      "출력 : 같은 하늘 아래 어딘가에 .\n",
      "입력 : 사랑해\n",
      "출력 : 하늘 만큼 땅 만큼 사랑해요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'하늘 만큼 땅 만큼 사랑해요 .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('내일 날씨는 어때?')\n",
    "sentence_generation('어떤 영화 좋아해?')\n",
    "sentence_generation('오늘 뭐 먹지?')\n",
    "sentence_generation('피곤하고 잠와')\n",
    "sentence_generation('사랑해')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee023d01",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- 처음에 돌렸을 때는 괜찮은 결과가 나왔는데 Restart로 전체로 다시 돌리니 이상하게 나와서 당황스러웠음 처음 나온건 이것보다 잘 나왔는데 똑같이 나와야지 왜 바뀌어서 다른 문장이 나오는지 이해가 되지 않음. \n",
    "- 한국어에 맞게 데이터 전처리를 해봄(조원들이 숫자까지 얘기해줘서 숫자도 전처리에 넣음)\n",
    "- 뉴스요약 익스에서 사용했던 코드를 그대로 가져와서 문장 길이를 보면서 MAX_LENGTH의 기준을 잡을 때 도움이 됨\n",
    "- 다른 길이로는 안해보고 11로만 했는데 길이가 달라짐에 따라 결과물도 많이 달라진다는 것을 성돈님께 듣게 되었고, 11로 했을 때 결과물이 괜찮았다고 해주셨다. 다행히 처음에 기준을 잘 잡아서 실행한 것 같다. \n",
    "- 위에 결과를 봤을 때 그닥 확 마음에 들지는 않았는데 이게 괜찮은 결과물이라니 나름 괜찮게 대답한것도 있지만 수정이 많이 필요하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934af2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
